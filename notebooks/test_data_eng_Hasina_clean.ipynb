{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de93a024",
   "metadata": {
    "id": "Q5RRwq_6gA5Y"
   },
   "source": [
    "Charger & nettoyer le dataset\n",
    "On nettoie :\n",
    "- lignes \"Order Date\" répétées (headers dupliqués)\n",
    "- types : quantity, price, dates\n",
    "- suppression des valeurs invalides (quantité/prix <= 0)\n",
    "- création de `zone = \"City (ST)\"` depuis `Purchase Address`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e42bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "yOGF2Z-gfuo4",
    "outputId": "b07f8bfb-4c6c-4220-8020-7f855cf34472"
   },
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RAW_URL = \"https://raw.githubusercontent.com/ralesabelou-glitch/data-test/main/all_data.csv\"\n",
    "TARGETS = [\"ThinkPad Laptop\", \"AAA Batteries (4-pack)\"]\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "df = pd.read_csv(RAW_URL)\n",
    "\n",
    "# 1) supprimer headers dupliqués\n",
    "df = df[df[\"Order Date\"].astype(str).str.lower() != \"order date\"].copy()\n",
    "\n",
    "# 2) types\n",
    "df[\"Quantity Ordered\"] = pd.to_numeric(df[\"Quantity Ordered\"], errors=\"coerce\")\n",
    "df[\"Price Each\"] = pd.to_numeric(df[\"Price Each\"], errors=\"coerce\")\n",
    "df[\"Order Date\"] = pd.to_datetime(df[\"Order Date\"], errors=\"coerce\")\n",
    "\n",
    "# 3) enlever invalides\n",
    "df = df.dropna(subset=[\"Order Date\", \"Purchase Address\", \"Product\", \"Quantity Ordered\", \"Price Each\"])\n",
    "df = df[(df[\"Quantity Ordered\"] > 0) & (df[\"Price Each\"] > 0)].copy()\n",
    "\n",
    "# 4) zone \"City (ST)\"\n",
    "def extract_city_state(addr: str):\n",
    "    parts = [p.strip() for p in str(addr).split(\",\")]\n",
    "    if len(parts) < 3:\n",
    "        return np.nan, np.nan\n",
    "    city = parts[-2]\n",
    "    last = parts[-1].split()\n",
    "    state = last[0] if len(last) >= 1 else np.nan\n",
    "    return city, state\n",
    "\n",
    "df[[\"city\", \"state\"]] = df[\"Purchase Address\"].apply(lambda x: pd.Series(extract_city_state(x)))\n",
    "df = df.dropna(subset=[\"city\", \"state\"]).copy()\n",
    "df[\"zone\"] = df[\"city\"].astype(str).str.strip() + \" (\" + df[\"state\"].astype(str).str.strip() + \")\"\n",
    "\n",
    "# 5) featurs\n",
    "df[\"revenue\"] = df[\"Quantity Ordered\"] * df[\"Price Each\"]\n",
    "df[\"year_month\"] = df[\"Order Date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553a3be",
   "metadata": {
    "id": "fxh0rPD6gC0P"
   },
   "source": [
    "## 2) Focus sur les 2 produits demandés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d4c04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "z5IFCcPegEan",
    "outputId": "8c2f3c47-5e0d-458e-b793-f80fb73a9517"
   },
   "outputs": [],
   "source": [
    "df2 = df[df[\"Product\"].isin(TARGETS)].copy()\n",
    "df2[\"Product\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e044d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SkiE5qurhmQ-",
    "outputId": "22b0124a-8816-4ef0-d9f2-46025752c5da"
   },
   "outputs": [],
   "source": [
    "monthly = (\n",
    "    df2.groupby([\"Product\", \"zone\", \"year_month\"], as_index=False)\n",
    "       .agg(\n",
    "           units=(\"Quantity Ordered\", \"sum\"),\n",
    "           revenue=(\"revenue\", \"sum\"),\n",
    "           orders=(\"Order ID\", \"nunique\")\n",
    "       )\n",
    "       .sort_values([\"Product\",\"zone\",\"year_month\"])\n",
    ")\n",
    "monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14b29e",
   "metadata": {
    "id": "wooF-9WDh-ZQ"
   },
   "source": [
    "Modèle baseline (scoring) : EWMA + growth_3m\n",
    "\n",
    "- j' ai chosi EWMA(span=3) car ca donne plus de poids aux mois récents (proxy de la demande future)\n",
    "- growth_3m : croissance relative entre le mois actuel et il y a 3 mois\n",
    "\n",
    "Score final :\n",
    "score = 0.7 * EWMA_last + 0.3 * (growth_3m clipped) * mean(EWMA_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455897c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "iqSZwvogh_dG",
    "outputId": "d3ee4861-aa25-4de3-f177-4a2b7db9b1f2"
   },
   "outputs": [],
   "source": [
    "def score_zones(product_name: str, span=3):\n",
    "    sub = monthly[monthly[\"Product\"] == product_name].copy()\n",
    "    piv = sub.pivot_table(index=\"year_month\", columns=\"zone\", values=\"units\", aggfunc=\"sum\").fillna(0).sort_index()\n",
    "\n",
    "    ewma = piv.ewm(span=span, adjust=False).mean()\n",
    "    ewma_last = ewma.iloc[-1]\n",
    "\n",
    "    if len(piv) >= 4:\n",
    "        growth_3m = (piv.iloc[-1] - piv.iloc[-4]) / (piv.iloc[-4] + 1e-9)\n",
    "    else:\n",
    "        growth_3m = pd.Series(0.0, index=piv.columns)\n",
    "\n",
    "    score = 0.7 * ewma_last + 0.3 * (growth_3m.clip(-1, 5) * ewma_last.mean())\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"zone\": score.index,\n",
    "        \"score\": score.values,\n",
    "        \"units_ewma_last\": ewma_last.values,\n",
    "        \"growth_3m\": growth_3m.values,\n",
    "    }).sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return out, piv\n",
    "\n",
    "baseline = {}\n",
    "pivots = {}\n",
    "for p in TARGETS:\n",
    "    baseline[p], pivots[p] = score_zones(p, span=3)\n",
    "\n",
    "baseline[\"ThinkPad Laptop\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23689a7",
   "metadata": {
    "id": "wUKPIHzBhcXC"
   },
   "source": [
    "Modèle ML : prédiction de la demande du mois suivant (forecast)\n",
    "\n",
    "Approche :\n",
    "- pivot zones × mois\n",
    "- transformation supervised (long format)\n",
    "- features : zone (one-hot), month/year, lags (t-1,t-2,t-3)\n",
    "- modèle : HistGradientBoostingRegressor\n",
    "- évaluation : MAE sur le dernier mois disponible\n",
    "- prédiction : mois suivant pour chaque zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05084f8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTV9NjjpfyyZ",
    "outputId": "f447c6ec-8bb9-4368-b38b-b95ee43b5eba"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "def build_supervised(product_name: str, max_lag=3):\n",
    "    sub = monthly[monthly[\"Product\"] == product_name].copy()\n",
    "    piv = sub.pivot_table(index=\"year_month\", columns=\"zone\", values=\"units\", aggfunc=\"sum\").fillna(0).sort_index()\n",
    "\n",
    "    long = piv.reset_index().melt(id_vars=\"year_month\", var_name=\"zone\", value_name=\"units\")\n",
    "    long = long.sort_values([\"zone\", \"year_month\"])\n",
    "\n",
    "    for k in range(1, max_lag + 1):\n",
    "        long[f\"lag_{k}\"] = long.groupby(\"zone\")[\"units\"].shift(k)\n",
    "\n",
    "    long[\"year\"] = long[\"year_month\"].dt.year\n",
    "    long[\"month\"] = long[\"year_month\"].dt.month\n",
    "\n",
    "    long = long.dropna(subset=[f\"lag_{k}\" for k in range(1, max_lag + 1)]).copy()\n",
    "    return long\n",
    "\n",
    "def forecast_next_month(product_name: str):\n",
    "    data = build_supervised(product_name, max_lag=3)\n",
    "\n",
    "    last_month = data[\"year_month\"].max()\n",
    "    train = data[data[\"year_month\"] < last_month].copy()\n",
    "    test  = data[data[\"year_month\"] == last_month].copy()\n",
    "\n",
    "    X_train = train[[\"zone\", \"year\", \"month\", \"lag_1\", \"lag_2\", \"lag_3\"]]\n",
    "    y_train = train[\"units\"]\n",
    "    X_test  = test[[\"zone\", \"year\", \"month\", \"lag_1\", \"lag_2\", \"lag_3\"]]\n",
    "    y_test  = test[\"units\"]\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        (\"zone\", OneHotEncoder(handle_unknown=\"ignore\"), [\"zone\"]),\n",
    "        (\"num\", \"passthrough\", [\"year\", \"month\", \"lag_1\", \"lag_2\", \"lag_3\"])\n",
    "    ])\n",
    "\n",
    "    model = HistGradientBoostingRegressor(random_state=42)\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    pred_test = pipe.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, pred_test)\n",
    "\n",
    "    # next month\n",
    "    next_month_dt = pd.Timestamp(last_month) + pd.offsets.MonthBegin(1)\n",
    "    last = data[data[\"year_month\"] == last_month].copy()\n",
    "    last[\"year\"] = next_month_dt.year\n",
    "    last[\"month\"] = next_month_dt.month\n",
    "\n",
    "    X_next = last[[\"zone\", \"year\", \"month\", \"lag_1\", \"lag_2\", \"lag_3\"]]\n",
    "    last[\"pred_units_next_month\"] = pipe.predict(X_next)\n",
    "\n",
    "    out = last.groupby(\"zone\", as_index=False)[\"pred_units_next_month\"].mean()\n",
    "    out = out.sort_values(\"pred_units_next_month\", ascending=False)\n",
    "\n",
    "    return out, mae\n",
    "\n",
    "ml_forecasts = {}\n",
    "ml_mae = {}\n",
    "for p in TARGETS:\n",
    "    ml_forecasts[p], ml_mae[p] = forecast_next_month(p)\n",
    "\n",
    "ml_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33638c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ECtK3swheaN",
    "outputId": "7b79c8ce-7bdc-4ca7-938c-40029eee80bf"
   },
   "outputs": [],
   "source": [
    "for p in TARGETS:\n",
    "    print(\"\\n==== TOP 10 zones (prévision ML mois suivant) —\", p, \"====\")\n",
    "    print(ml_forecasts[p].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07651f33",
   "metadata": {
    "id": "ziGau8SDhyUu"
   },
   "source": [
    "Heatmap : zones vs mois (unités)\n",
    "On prend les Top N zones et on affiche une matrice (zones en lignes, mois en colonnes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19cd88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0ANuiW4mh0S6",
    "outputId": "350edf64-5b6a-4e69-937a-56f6f32ef6d7"
   },
   "outputs": [],
   "source": [
    "def plot_zone_month_heatmap(product: str, top_n=20):\n",
    "    piv = pivots[product]\n",
    "    top_zones = baseline[product].head(top_n)[\"zone\"].tolist()\n",
    "    mat = piv[top_zones].T  # zones x months\n",
    "\n",
    "    plt.figure(figsize=(10, 0.35*top_n + 2))\n",
    "    plt.imshow(mat, aspect=\"auto\")\n",
    "    plt.title(f\"Heatmap unités — {product} (Top {top_n} zones)\")\n",
    "    plt.xlabel(\"Mois\")\n",
    "    plt.ylabel(\"Zone\")\n",
    "    plt.xticks(range(len(mat.columns)), [c.strftime(\"%Y-%m\") for c in mat.columns], rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(mat.index)), mat.index)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_zone_month_heatmap(\"ThinkPad Laptop\", top_n=20)\n",
    "plot_zone_month_heatmap(\"AAA Batteries (4-pack)\", top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10936387",
   "metadata": {
    "id": "ievqVvS2i7iF"
   },
   "source": [
    "Assistant règles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347aced9",
   "metadata": {
    "id": "8d1hgB1Di8Db"
   },
   "outputs": [],
   "source": [
    "ZONE_PATTERN = re.compile(r\"([A-Za-z .'\\-]+)\\s*\\(\\s*([A-Za-z]{2})\\s*\\)\", re.IGNORECASE)\n",
    "\n",
    "def extract_zones_from_text(text: str):\n",
    "    matches = ZONE_PATTERN.findall(text or \"\")\n",
    "    zones = []\n",
    "    for city, stt in matches:\n",
    "        zones.append(f\"{city.strip()} ({stt.strip().upper()})\")\n",
    "    # unique preserve order\n",
    "    out, seen = [], set()\n",
    "    for z in zones:\n",
    "        if z not in seen:\n",
    "            out.append(z); seen.add(z)\n",
    "    return out\n",
    "\n",
    "def compare_zones(product: str, zone_a: str, zone_b: str, piv: pd.DataFrame, scores_df: pd.DataFrame) -> str:\n",
    "    if zone_a not in piv.columns or zone_b not in piv.columns:\n",
    "        missing = [z for z in [zone_a, zone_b] if z not in piv.columns]\n",
    "        return f\"Zones introuvables dans les données pour **{product}** : {', '.join(missing)}.\"\n",
    "\n",
    "    a_series, b_series = piv[zone_a], piv[zone_b]\n",
    "    a_last, b_last = float(a_series.iloc[-1]), float(b_series.iloc[-1])\n",
    "    a_total, b_total = float(a_series.sum()), float(b_series.sum())\n",
    "\n",
    "    a_score = float(scores_df.loc[scores_df[\"zone\"] == zone_a, \"score\"].iloc[0])\n",
    "    b_score = float(scores_df.loc[scores_df[\"zone\"] == zone_b, \"score\"].iloc[0])\n",
    "\n",
    "    winner = zone_a if a_score > b_score else zone_b\n",
    "    return (\n",
    "        f\"Comparaison **{product}** :\\n\"\n",
    "        f\"- **{zone_a}** → dernier mois={a_last:.0f}, total={a_total:.0f}, score={a_score:.2f}\\n\"\n",
    "        f\"- **{zone_b}** → dernier mois={b_last:.0f}, total={b_total:.0f}, score={b_score:.2f}\\n\"\n",
    "        f\"➡️ Zone prioritaire : **{winner}**.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0b9c0",
   "metadata": {
    "id": "1Thv5QE8iy2H"
   },
   "source": [
    "Assistant LLM OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe845aad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297,
     "referenced_widgets": [
      "8308338bbae64677901f3ae6451b65d7",
      "34175314b5bd4ea8bd8829c23ab25b75",
      "11a4f612c84c43b5a46bc27bb28c5d03",
      "c1bff4a12b9c47d89dfb165227b029e6",
      "58db6c410cd4409abe3c0f7afb8cf77d",
      "d9a4b3d4d28246b196419a5416b29ac9",
      "503383dc7276497ea55a5d05a809d530",
      "12dd1b809c0e4ed2be79e742d78af2dc",
      "a5f76247b2d04b008b5c1ee79b12b274",
      "f338a040bb77414bbdb60d47f4749b5f",
      "f51a11bb99f54034a1bc5de665358263",
      "f4fbcdbc24e84c86b45dca26e75a1f21",
      "b856773ec62f48c79c22d9da03652f32",
      "90a77811af6c48d683137810e4deae91",
      "c4d83bc693d24abfb586227fb00894ea",
      "7537f49e81f0453fbce309f8e59a9199",
      "9d83cc2337764c6791902723c9a479e1",
      "69cae98ec2a248e4b28486e558c59dcd",
      "3a5cf8a973d547518c5261c5c941e6fd",
      "64bfd1298dc34341a086ce3cb721fdaa",
      "294ee9b8a5d84d4483269381d2831df3",
      "ef9d33dc5f6747078bb898f7b32415aa",
      "3a0c1dc2dd6b4bd5aa4448352ceb25ba",
      "b9acb79b936747a197451e63b57b17c3",
      "a17dc026f4c7432ca155ab8733d927bc",
      "8884e40ed7694c8d8d9f76dd868dbe11",
      "256b7f8463a7467f885947a76cb066db",
      "8f8a1d738e0a4d73ae98479dba1889f7",
      "f4618e6014914382b03607e232f75699",
      "1de5b06edd914354a6630eb00034cd35",
      "990211d0a1404884bf4f7d076de54879",
      "ecc4778bbf99401aac69ad8da6d75123",
      "f39585969e55493289a1e28d96e29a68",
      "612213fd91f2407bac30d7dd8a75148d",
      "85658aa1885345a4a7de8253b6edfbae",
      "a33f496314c54d1881df1ab1e62a17a0",
      "57bb9b4bb4a04514956a496bc24fb8fe",
      "1049fb57a8b04929be100faef478a73d",
      "598be40920f844a5b8c2ba492b22f787",
      "7481c6d404074236a1572505f0d26624",
      "33be89cc955041b3ae6d1c2c749fa625",
      "2d8e4a4676634749bc9f7305501eb92a",
      "45b15ca086244875b9b1b08802e7f7f5",
      "7ed93c516663460ebeafcf09be96b699",
      "2be1f7bee08144e79c3e45989faf33a7",
      "897ffb02b9294884a1d9fa21a75000fd",
      "05055287f4e04e09a5fe86b1a2679b25",
      "55c96c42511e41e3bdca30e45295fc38",
      "827fad5949be4824bd7cbb8f2e5cc322",
      "dd44efa4663641c0b1f568b0f4d15634",
      "db8bdcb802a044cd95b2c0622776883a",
      "7ca257e749214ee5ac1cc7d31b56d082",
      "969a4b9c675c4f08be9f386696f627f7",
      "ab642560d55949319fcdbf68dafecc04",
      "6f7661e65aa44bb884da70432e06108d",
      "4db21c16f5734f25840aff7d32c68bc2",
      "84d839ad683344789126598b62e2e0ab",
      "c9e1ba2447cf4345a1f9cd837ee7ee02",
      "3907fb34395e4b368dac31f339c97b9b",
      "1ece6c70ddc24b8c977d76ef5e8fa21c",
      "52fbc172731345e3bdd769aa30911a84",
      "7333848130ef4ebebf086bceef97806d",
      "3f7f2a32ef3e455fa8b5716ac8fce915",
      "6a15ceef1d4042699d308acadb3d3f5e",
      "8a5f53ddfa8042c28b34d77b4b116a74",
      "8454c9e0914d4a14a116f497269d01e0",
      "eee7143952dd437e9378fb566bf0b152",
      "c0beff8e75e0495da3f61d84b5fdc8b2",
      "048845448da1488e9f1ba04d1b8cc4c9",
      "31a34cc1d84a49abb229bf3c6af8b14c",
      "9852a12a2f9d42548369917542ccab6b",
      "fd0116b5b31c40ec9d232322fcad1878",
      "91d0e6c13eaf40088da3ddf00335af6f",
      "843d0f7c2a0648dc914cb2f90a273795",
      "3d46eae2bb424d7e8b9a056fd8ae2528",
      "e356794baabb43fc93cbd07467c75c9c",
      "db7270cd65814d3daf1f23fbe4b735f1"
     ]
    },
    "id": "-NLp8ry6hs-k",
    "outputId": "9d9fb3c8-1b4c-4afe-e710-ddf85e527030"
   },
   "outputs": [],
   "source": [
    "# !pip install -U transformers accelerate sentencepiece\n",
    "\n",
    "import json, re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "MODEL_ID = \"google/flan-t5-large\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_ID)\n",
    "\n",
    "ZONE_PATTERN = re.compile(r\"([A-Za-z .'\\-]+)\\s*\\(\\s*([A-Za-z]{2})\\s*\\)\", re.IGNORECASE)\n",
    "\n",
    "def extract_zones_from_text(text: str):\n",
    "    matches = ZONE_PATTERN.findall(text or \"\")\n",
    "    zones = []\n",
    "    for city, stt in matches:\n",
    "        zones.append(f\"{city.strip()} ({stt.strip().upper()})\")\n",
    "    out, seen = [], set()\n",
    "    for z in zones:\n",
    "        if z not in seen:\n",
    "            out.append(z); seen.add(z)\n",
    "    return out\n",
    "\n",
    "def compare_zones(product, zone_a, zone_b, piv, scores_df):\n",
    "    if zone_a not in piv.columns or zone_b not in piv.columns:\n",
    "        missing = [z for z in [zone_a, zone_b] if z not in piv.columns]\n",
    "        return f\"Zones introuvables: {missing}\"\n",
    "\n",
    "    a_series, b_series = piv[zone_a], piv[zone_b]\n",
    "    a_last, b_last = float(a_series.iloc[-1]), float(b_series.iloc[-1])\n",
    "    a_total, b_total = float(a_series.sum()), float(b_series.sum())\n",
    "    a_score = float(scores_df.loc[scores_df[\"zone\"] == zone_a, \"score\"].iloc[0])\n",
    "    b_score = float(scores_df.loc[scores_df[\"zone\"] == zone_b, \"score\"].iloc[0])\n",
    "    winner = zone_a if a_score > b_score else zone_b\n",
    "\n",
    "    return (\n",
    "        f\"Comparaison {product}:\\n\"\n",
    "        f\"- {zone_a}: dernier mois={a_last:.0f}, total={a_total:.0f}, score={a_score:.2f}\\n\"\n",
    "        f\"- {zone_b}: dernier mois={b_last:.0f}, total={b_total:.0f}, score={b_score:.2f}\\n\"\n",
    "        f\"Zone prioritaire: {winner}\"\n",
    "    )\n",
    "\n",
    "def flan_generate(prompt: str, max_new_tokens: int = 256) -> str:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False\n",
    "        )\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "def llm_answer(product: str, question: str) -> str:\n",
    "    scores_df = baseline[product]\n",
    "    piv = pivots[product]\n",
    "\n",
    "    deterministic = None\n",
    "    ql = (question or \"\").lower()\n",
    "    if (\"compare\" in ql) or (\"entre\" in ql):\n",
    "        zones = extract_zones_from_text(question)\n",
    "        if len(zones) >= 2:\n",
    "            deterministic = compare_zones(product, zones[0], zones[1], piv, scores_df)\n",
    "\n",
    "    context = {\n",
    "        \"product\": product,\n",
    "        \"top_zones\": scores_df.head(15).to_dict(orient=\"records\"),\n",
    "        \"computed_comparison\": deterministic,\n",
    "        \"rules\": [\n",
    "            \"Ne jamais inventer de zones ou de chiffres\",\n",
    "            \"Si stock -> top 5 zones par score\",\n",
    "            \"Si progression -> max growth_3m\",\n",
    "            \"Si comparaison -> utiliser computed_comparison\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Tu es un assistant logistique d'aide à la décision.\n",
    "\n",
    "CONTEXTE (résultats calculés):\n",
    "{json.dumps(context, ensure_ascii=False)}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "Réponds en français, concis, actionnable. Ne jamais inventer.\n",
    "\"\"\".strip()\n",
    "\n",
    "    return flan_generate(prompt, max_new_tokens=220)\n",
    "\n",
    "print(llm_answer(\"ThinkPad Laptop\", \"Où devrais-je augmenter les stocks de ThinkPad Laptop ?\"))\n",
    "#print(llm_answer(\"ThinkPad Laptop\", \"Quelle ville montre la plus forte progression de la demande ?\"))\n",
    "#print(llm_answer(\"ThinkPad Laptop\", \"Compare la demande entre Dallas (TX) et Houston (TX)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84db3c",
   "metadata": {
    "id": "UnSx9U_TjE3g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
